{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kobert-transformers"
      ],
      "metadata": {
        "id": "jihxBQUNSQ3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "zmsSH_0pQUMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM8tco8tPkHR"
      },
      "outputs": [],
      "source": [
        "train = pd.read_table(\"/content/ratings_train.txt\")\n",
        "test = pd.read_table(\"/content/ratings_test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()\n",
        "test.head()"
      ],
      "metadata": {
        "id": "3f23KCurQoMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "2FhEV82ERINQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리: 결측치 제거\n",
        "train = train.dropna(subset=['document'])\n",
        "test = test.dropna(subset=['document'])"
      ],
      "metadata": {
        "id": "a-XBSiWDSE_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kobert_transformers import get_kobert_model, get_tokenizer\n",
        "from torch.optim import AdamW\n",
        "\n",
        "# KoBERT 모델 및 토크나이저 로드\n",
        "model = get_kobert_model()\n",
        "tokenizer = get_tokenizer()\n"
      ],
      "metadata": {
        "id": "cDvwN_-mSIlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch 데이터셋 및 데이터 로더 정의\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": torch.tensor(label)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "# 데이터셋 준비\n",
        "train_dataset = SentimentDataset(train['document'].tolist(), train['label'].tolist(), tokenizer)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n"
      ],
      "metadata": {
        "id": "WSgVNj75SLCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 및 평가\n",
        "import torch.nn as nn\n",
        "\n",
        "# 감성 분석을 위한 분류 모델 정의\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, bert_model, num_classes=2):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs[1]\n",
        "        output = self.dropout(pooled_output)\n",
        "        return self.classifier(output)\n",
        "\n",
        "# 모델 초기화\n",
        "model = SentimentClassifier(model)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# 학습 루프 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(3):  # 원하는 epoch 수 설정\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "W0qV77B3SgLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    model.eval()\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
        "    outputs = model(inputs['input_ids'], inputs['attention_mask'])\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    positive_percent = probs[0][1].item() * 100  # 긍정 확률\n",
        "    return positive_percent\n",
        "\n",
        "# 예측 예시\n",
        "text = \"이 영화 정말 재미있다!\"\n",
        "positive_percent = predict_sentiment(text)\n",
        "print(f\"긍정 비율: {positive_percent:.2f}%\")\n"
      ],
      "metadata": {
        "id": "cVPpdYBzSojd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SWho_cxCSwvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}